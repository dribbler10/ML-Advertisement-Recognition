\section{Описание задачи и методологии работы}
\subsection{Задача и набор данных}
Выбранная для тестирования методов задача заключается в определении, является ли элемент видеопотока телевизионной рекламой. Наша группа не занималась получением признакового описания из видеороликов, а лишь проводила эксперименты на готовом наборе данных, полученном исследователями в \cite{vyas}. Авторы указанной работы преобразовали 150 часов видео с 5 новостных каналов (BBC, CNN, CNN-IBN, NDTV, TIMES NOW) в признаковые описания коротких видеофрагментов, упорядоченных хронологически. Набор данных включает визуальные (длительность фрагмента, распределение разности кадров, распределение движения, распределение текста на экране и процент движущихся границ объектов на видео) и аудиопризнаки (спектральные характеристики аудиосигнала и bag of audio words). Каждому объекту в наборе данных присвоена метка класса: \(+1\) --- фрагмент является рекламой, \(-1\) --- не является. В таблице~\ref{table:class-distr} указаны соотношения классов в данных каждого из каналов:

\begin{table}
    \centering
    \begin{tabular}{|p{4cm}||c|c|c|c|c|}
    \hline
    Канал & BBC & CNN & CNN-IBN & TIMES NOW & NDTV \\ \hline
    Число объектов & 17720 & 22545 & 33117 & 39252 & 17051 \\ \hline
    \% объектов, соответствующих рекламе & 47.5 & 63.9 & 65.5 & 64 & 73.7\\
    \hline
    \end{tabular}
    \caption{Соотношение классов в наборе данных}
    \label{table:class-distr}
\end{table}

\subsection{Методология}
При рассмотрении методов отбора признаков и эталонов нас интересовало то, как их работа отражается на качестве классификации базовых методов машинного обучения и на времени, требующемся для их обучения. Исходя из этого мы структурировали эксперименты следующим образом:
\begin{enumerate}
    \item Использование базовых методов машинного обучения\\
    Были проведены эксперименты с 5 базовыми методами (см.~\ref{sec:base-methods}) на данных с каждого видеоканала, с изменением одного параметра по некоторой сетке. Для каждого сочетания (метод, канал, значение параметра) была проведена 10-кратная кросс-валидация, в результате которой были получены среднее значение и стандартное отклонение для качества классификации и времени обучения. На основе результатов данной работы мы выбрали по одному значению параметров для каждого метода (из тех, которые имеют параметры) и использовали их в следующих частях работы.
    \item Использование методов отбора признаков\\\label{item:feature-selection}
    Были проведены эксперименты с некоторыми методами отбора признаков по схеме, аналогичной предыдущему пункту, с тем отличием, что в данном случае варьировался параметр метода отбора признаков.
    \item Использование методов отбора эталонов\\
    Аналогично п.\ref{item:feature-selection}.
\end{enumerate}

\subsection{Используемые методы}\label{sec:base-methods}
Мы выбрали 5 методов машинного обучения в качестве базовых, в этом разделе приводятся их описания и результаты, показанные методами для разных параметров.

\subsubsection{\(k\) ближайших соседей}
\(k\)NN --- простой метрический метод, относящий \(\mathbf{x}\) в мажоритарный класс \(k\) ближайших (в нашем случае в евклидовой метрике) соседей из обучающей выборки. Он относится к категории методов так называемого ленивого обучения --- фаза обучения у него состоит лишь в сохранении тестовой выборки полностью. При классификации он проходит по всем объектам обучающей выборки, вычисляя расстояния до классифицируемого объекта, что может выливаться в длительное время работы. Использованная нами реализация метода сохраняет обучающую выборку в KD-дерево, что несколько нивелирует данный негативный эффект. Известно, что \(k\)NN может показывать неудовлетворительные результаты в задачах с сильно многомерным пространством признаков, из-за того, что ближайшие к классифицируемому векторы все оказываются на примерно одинаковом расстоянии от него в евклидовой метрике \cite{beyer}. Также, ленивость \(k\)NN выливается в высокие требования к объёму памяти при работе с большими наборами данных. Эти особенности обуславливают наш интерес к методу \(k\)NN в рамках данной работы.

В тестовых запусках использовались значения параметра \(k\in\{1,3,5,\dotsc,101\}\). На рис.~\ref{fig:knn-base} представлены зависимости качества классификации от \(k\) для разных каналов.

\subsubsection{Линейный дискриминантный анализ}
Линейный дискриминантный анализ в задаче бинарной классификации использует предположения о том, что объекты обоих классов распределены в пространстве признаков нормально, и что матрицы матрицы ковариации этих распределений совпадают. При данных предположениях уравнение разделяющей поверхности, получаемое из принципа максимума апостериорной вероятности, оказывается линейным. Таким образом, в задаче бинарной классификации LDA строит разделяющую гиперплоскость.

LDA в отличие от остальных рассматриваемых методов не имеет настраиваемых параметров. Результаты его работы представлены в сводной таблице~\ref{table:base-all}.

\subsubsection{Машина опорных векторов}
\subsubsection{Случайный лес}
\subsubsection{Градиентный бустинг деревьев решений}
\subsubsection{Результаты для выбранных параметров}
В результате использования методов, описанных в данном разделе, были выбраны параметры, с которыми они будут запускаться после отбора признаков или эталонов. В таблице~\ref{table:base-all} сведена вся информация о качестве классификации и производительности методов для выбранных значений параметров.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c||c|c|c|c|c|}
    \cline{2-6}
    \multicolumn{1}{c||}{} & \(k\)NN & LDA & Random forest & SVM & GTB \\
    \hline \hline
    CNN & \tworowcell{\(Q=78\%\)}{\(T_{train}=0.32 s\)} & \tworowcell{\(Q=90.4\%\)}{\(T_{train}=0.006 s\)} & \tworowcell{\(Q=92.2\%\)}{\(T_{train}=15.8 s\)} & \tbd{No data} & \tbd{No data} \\ \hline
    BBC & \tworowcell{\(Q=77.2\%\)}{\(T_{train}=0.37 s\)} & \tworowcell{\(Q=84.2\%\)}{\(T_{train}=0.003 s\)} & \tworowcell{\(Q=85.4\%\)}{\(T_{train}=9.3 s\)} & \tbd{No data} & \tbd{No data} \\ \hline
    CNN-IBN & & & & \tbd{No data} & \tbd{No data} \\ \hline
    TIMES NOW & & & & \tbd{No data} & \tbd{No data} \\ \hline
    NDTV & & & & \tbd{No data} & \tbd{No data} \\ \hline
    \end{tabular}
    \caption{Сводная таблица результатов базовых методов}
    \label{table:base-all}
\end{table}

